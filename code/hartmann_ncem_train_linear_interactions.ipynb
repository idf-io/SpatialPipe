{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train linear NCEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ncem\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_rel, ttest_ind\n",
    "\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# paths\n",
    "data_path_base =\"../input-data/raw-data/\"\n",
    "out_path = \"../output-data/Hartmann-2021/\"\n",
    "fn_out_cv = out_path + \"/results/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If errors occur with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If `InternalError: libdevice not found at ./libdevice.10.bc [Op:__inference_one_e_step_2806]`\n",
    "# --> try including in shell $PATH:\n",
    "#        `export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda`\n",
    "\n",
    "# If `\"Attempting to perform BLAS operation using StreamExecutor without BLAS support`\n",
    "# --> try setting a dedicated amount of GPU vram:\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=500)]) # 1500 [MB]\n",
    "    except RuntimeError as e:\n",
    "        print('ERROR')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset specific inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'hartmann'\n",
    "data_path = data_path_base + '/Hartmann-2021/'\n",
    "log_transform = False # Hartmann DS is already arcsinh transformed\n",
    "use_domain = True\n",
    "scale_node_size=False\n",
    "merge_node_types_predefined = True\n",
    "covar_selection = []\n",
    "output_layer='linear'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = 'interactions'\n",
    "optimizer = 'adam'\n",
    "domain_type = 'patient'\n",
    "\n",
    "learning_rate = 0.05\n",
    "l1 = 0.\n",
    "l2 = 0.\n",
    "\n",
    "batch_size = 58\n",
    "radius = 35\n",
    "n_eval_nodes = 10\n",
    "\n",
    "gs_id = f\"tutorial_{model_class}_{radius}_{data_set}_{domain_type}\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv = 3\n",
    "epochs = 2000 if \"tutorial\" not in gs_id else 10 \n",
    "epochs_warmup = 0\n",
    "max_steps_per_epoch = 20\n",
    "patience = 100\n",
    "lr_schedule_min_lr = 1e-10\n",
    "lr_schedule_factor = 0.5\n",
    "lr_schedule_patience = 50\n",
    "val_bs = 16\n",
    "max_val_steps_per_epoch = 10\n",
    "shuffle_buffer_size = None\n",
    "\n",
    "feature_space_id = \"standard\"\n",
    "cond_feature_space_id = \"type\"\n",
    "\n",
    "use_covar_node_label = False\n",
    "use_covar_node_position = False\n",
    "use_covar_graph_covar = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ncem.train.TrainModelInteractions()\n",
    "trainer.init_estim(log_transform=log_transform)\n",
    "\n",
    "trainer.estimator.get_data(\n",
    "    data_origin=data_set,\n",
    "    data_path=data_path,\n",
    "    radius=radius,\n",
    "    graph_covar_selection=covar_selection,\n",
    "    node_label_space_id=cond_feature_space_id,\n",
    "    node_feature_space_id=feature_space_id,\n",
    "    # feature_transformation=transformation_dict[transform_key],\n",
    "    use_covar_node_position=use_covar_node_position,\n",
    "    use_covar_node_label=use_covar_node_label,\n",
    "    use_covar_graph_covar=use_covar_graph_covar,\n",
    "    # hold_out_covariate=hold_out_covariate,\n",
    "    domain_type=domain_type,\n",
    "    # merge_node_types_predefined=merge_node_types_predefined,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.estimator.split_data_node(\n",
    "    validation_split=0.1,\n",
    "    test_split=0.1,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.estimator.init_model(\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    n_eval_nodes_per_graph=n_eval_nodes,\n",
    "\n",
    "    l2_coef=l2,\n",
    "    l1_coef=l1,\n",
    "    use_interactions=True,\n",
    "    use_domain=use_domain,\n",
    "    scale_node_size=scale_node_size,\n",
    "    output_layer=output_layer,\n",
    ")\n",
    "trainer.estimator.model.training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.estimator.train(\n",
    "    epochs=epochs,\n",
    "    epochs_warmup=epochs_warmup,\n",
    "    batch_size=batch_size,\n",
    "    max_steps_per_epoch=max_steps_per_epoch,\n",
    "    validation_batch_size=val_bs,\n",
    "    max_validation_steps=max_val_steps_per_epoch,\n",
    "    patience=patience,\n",
    "    lr_schedule_min_lr=lr_schedule_min_lr,\n",
    "    lr_schedule_factor=lr_schedule_factor,\n",
    "    lr_schedule_patience=lr_schedule_patience,\n",
    "    monitor_partition=\"val\",\n",
    "    monitor_metric=\"loss\",\n",
    "    shuffle_buffer_size=shuffle_buffer_size,\n",
    "    early_stopping=True,\n",
    "    reduce_lr_plateau=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_test = trainer.estimator.evaluate_any(\n",
    "    img_keys=trainer.estimator.img_keys_test,\n",
    "    node_idx=trainer.estimator.nodes_idx_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_per_node_type, evaluation_per_node_type = trainer.estimator.evaluate_per_node_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_per_node_type['Fibroblast']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "squidpyTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97543237a6bcd86b2473d592fc25336dd1965b4a1315473dfbc595ecc291a458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
